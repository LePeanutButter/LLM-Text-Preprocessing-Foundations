{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc9211ac",
   "metadata": {},
   "source": [
    "# Notebook - Embeddings and Sliding Windows\n",
    "\n",
    "**Escuela Colombiana de Ingeniería Julio Garavito**\n",
    "\n",
    "**Student**: Santiago Botero García\n",
    "\n",
    "This notebook implements the data preparation and embedding pipeline required to train an autoregressive language model.\n",
    "\n",
    "Each section corresponds to a critical stage in transforming raw text into numerical tensors suitable for neural network optimization.\n",
    "\n",
    "We progressively move from:\n",
    "\n",
    "Raw text &rarr; Token IDs &rarr; Sliding Windows &rarr; Batches &rarr; Embeddings\n",
    "\n",
    "Beyond implementation, each step is analyzed conceptually to understand its implications for:\n",
    "\n",
    "- Large Language Models (LLMs)\n",
    "- Neural representation learning\n",
    "- Agentic system architectures\n",
    "\n",
    "## Step 1: Setup and Dependencies\n",
    "\n",
    "This section initializes the computational environment required to reproduce the embedding pipeline.\n",
    "\n",
    "We import:\n",
    "\n",
    "- torch &rarr; for tensor computation and neural network modules\n",
    "- tiktoken &rarr; for GPT-style tokenization\n",
    "- Dataset and DataLoader &rarr; for structured batching\n",
    "\n",
    "We also fix the random seed to ensure reproducibility.\n",
    "\n",
    "Why this matters:\n",
    "\n",
    "LLMs are sensitive to initialization.\n",
    "Reproducibility is critical for debugging, experimentation, and evaluation.\n",
    "\n",
    "Even at this early stage, we are setting the foundation for deterministic training behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba08734f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.10.0-cp312-cp312-win_amd64.whl.metadata (31 kB)\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.12.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.24.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Using cached fsspec-2026.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Downloading setuptools-82.0.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2026.2.19-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests>=2.26.0 (from tiktoken)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.26.0->tiktoken)\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.26.0->tiktoken)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken)\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.26.0->tiktoken)\n",
      "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Downloading torch-2.10.0-cp312-cp312-win_amd64.whl (113.8 MB)\n",
      "   ---------------------------------------- 0.0/113.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 16.8/113.8 MB 96.0 MB/s eta 0:00:02\n",
      "   ------------- ------------------------- 40.1/113.8 MB 106.3 MB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 65.3/113.8 MB 109.6 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 90.7/113.8 MB 111.4 MB/s eta 0:00:01\n",
      "   -------------------------------------  113.5/113.8 MB 111.6 MB/s eta 0:00:01\n",
      "   -------------------------------------  113.5/113.8 MB 111.6 MB/s eta 0:00:01\n",
      "   -------------------------------------  113.5/113.8 MB 111.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 113.8/113.8 MB 71.9 MB/s  0:00:01\n",
      "Using cached tiktoken-0.12.0-cp312-cp312-win_amd64.whl (878 kB)\n",
      "Using cached fsspec-2026.2.0-py3-none-any.whl (202 kB)\n",
      "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "Using cached regex-2026.2.19-cp312-cp312-win_amd64.whl (277 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached filelock-3.24.3-py3-none-any.whl (24 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading setuptools-82.0.0-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 23.9 MB/s  0:00:00\n",
      "Installing collected packages: mpmath, urllib3, typing-extensions, sympy, setuptools, regex, networkx, MarkupSafe, idna, fsspec, filelock, charset_normalizer, certifi, requests, jinja2, torch, tiktoken\n",
      "\n",
      "   ----------------------------------------  0/17 [mpmath]\n",
      "   ----------------------------------------  0/17 [mpmath]\n",
      "   ----------------------------------------  0/17 [mpmath]\n",
      "   ----------------------------------------  0/17 [mpmath]\n",
      "   ----------------------------------------  0/17 [mpmath]\n",
      "   ----------------------------------------  0/17 [mpmath]\n",
      "   ----------------------------------------  0/17 [mpmath]\n",
      "   ----------------------------------------  0/17 [mpmath]\n",
      "   ----------------------------------------  0/17 [mpmath]\n",
      "   ----------------------------------------  0/17 [mpmath]\n",
      "   ----------------------------------------  0/17 [mpmath]\n",
      "   -- -------------------------------------  1/17 [urllib3]\n",
      "   -- -------------------------------------  1/17 [urllib3]\n",
      "   -- -------------------------------------  1/17 [urllib3]\n",
      "   -- -------------------------------------  1/17 [urllib3]\n",
      "   -- -------------------------------------  1/17 [urllib3]\n",
      "   ---- -----------------------------------  2/17 [typing-extensions]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   ------- --------------------------------  3/17 [sympy]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   --------- ------------------------------  4/17 [setuptools]\n",
      "   ----------- ----------------------------  5/17 [regex]\n",
      "   ----------- ----------------------------  5/17 [regex]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   -------------- -------------------------  6/17 [networkx]\n",
      "   ---------------- -----------------------  7/17 [MarkupSafe]\n",
      "   ------------------ ---------------------  8/17 [idna]\n",
      "   ------------------ ---------------------  8/17 [idna]\n",
      "   --------------------- ------------------  9/17 [fsspec]\n",
      "   --------------------- ------------------  9/17 [fsspec]\n",
      "   --------------------- ------------------  9/17 [fsspec]\n",
      "   --------------------- ------------------  9/17 [fsspec]\n",
      "   --------------------- ------------------  9/17 [fsspec]\n",
      "   --------------------- ------------------  9/17 [fsspec]\n",
      "   --------------------- ------------------  9/17 [fsspec]\n",
      "   ----------------------- ---------------- 10/17 [filelock]\n",
      "   ----------------------- ---------------- 10/17 [filelock]\n",
      "   ------------------------- -------------- 11/17 [charset_normalizer]\n",
      "   ------------------------- -------------- 11/17 [charset_normalizer]\n",
      "   ---------------------------- ----------- 12/17 [certifi]\n",
      "   ---------------------------- ----------- 12/17 [certifi]\n",
      "   ------------------------------ --------- 13/17 [requests]\n",
      "   ------------------------------ --------- 13/17 [requests]\n",
      "   ------------------------------ --------- 13/17 [requests]\n",
      "   -------------------------------- ------- 14/17 [jinja2]\n",
      "   -------------------------------- ------- 14/17 [jinja2]\n",
      "   -------------------------------- ------- 14/17 [jinja2]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ----------------------------------- ---- 15/17 [torch]\n",
      "   ------------------------------------- -- 16/17 [tiktoken]\n",
      "   ------------------------------------- -- 16/17 [tiktoken]\n",
      "   ---------------------------------------- 17/17 [tiktoken]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 certifi-2026.1.4 charset_normalizer-3.4.4 filelock-3.24.3 fsspec-2026.2.0 idna-3.11 jinja2-3.1.6 mpmath-1.3.0 networkx-3.6.1 regex-2026.2.19 requests-2.32.5 setuptools-82.0.0 sympy-1.14.0 tiktoken-0.12.0 torch-2.10.0 typing-extensions-4.15.0 urllib3-2.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\santi\\OneDrive\\Documents\\LLM-Text-Preprocessing-Foundations\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:283: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2124290e6b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install torch tiktoken\n",
    "\n",
    "import torch\n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34042b48",
   "metadata": {},
   "source": [
    "## Step 2: Loading and Inspecting the Text\n",
    "\n",
    "In this section, we load the raw text file that will serve as our training data.\n",
    "\n",
    "This text is the only supervision signal the model will receive.\n",
    "\n",
    "We inspect:\n",
    "\n",
    "- Total character count\n",
    "- A preview of the content\n",
    "\n",
    "Why this matters:\n",
    "\n",
    "Before tokenization, the model has no structure.\n",
    "The corpus determines:\n",
    "\n",
    "- Vocabulary richness\n",
    "- Context diversity\n",
    "- Statistical regularities the model can learn\n",
    "\n",
    "All semantic structure that will later emerge in embeddings\n",
    "originates from this raw sequence of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a277fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\n",
      "\n",
      "\"The height of his glory\"--that was what the women called it. I can hear Mrs. Gideon Thwing--his last Chicago sitter--deploring his unaccountable abdication. \"Of course it'\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(\"Total characters:\", len(text))\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156464ed",
   "metadata": {},
   "source": [
    "## Step 3: Tokenization with tiktoken\n",
    "\n",
    "Here we transform raw text into discrete token IDs using GPT-2 tokenization.\n",
    "\n",
    "The tokenizer converts text into integers that correspond to subword units.\n",
    "\n",
    "This step performs the mapping:\n",
    "\n",
    "Natural language &rarr; Discrete symbolic representation\n",
    "\n",
    "Why this is critical:\n",
    "\n",
    "Neural networks operate on numbers, not strings.\n",
    "Tokenization defines:\n",
    "\n",
    "- Vocabulary size $V$\n",
    "- The dimensionality of the embedding matrix $V\\times d$\n",
    "- The atomic prediction units of the model\n",
    "\n",
    "Tokenization is not just preprocessing -\n",
    "it defines the representational granularity of the entire model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a6fc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 5145\n",
      "First 20 token IDs: [40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138, 257, 7026, 15632, 438, 2016, 257, 922, 5891, 1576, 438]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = tokenizer.encode(text)\n",
    "\n",
    "print(\"Total tokens:\", len(token_ids))\n",
    "print(\"First 20 token IDs:\", token_ids[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be0a62f",
   "metadata": {},
   "source": [
    "## Step 4: Building Input-Target Pairs (Sliding Window)\n",
    "\n",
    "This section creates supervised learning examples from a single long token sequence.\n",
    "\n",
    "We generate pairs:\n",
    "\n",
    "Input  $\\rarr x_0 ... x_n$  \n",
    "Target $\\rarr x_1 ... x_{n+1}$\n",
    "\n",
    "Each pair trains the model to predict the next token.\n",
    "\n",
    "The sliding window moves across the corpus with a configurable stride.\n",
    "\n",
    "Why this is important:\n",
    "\n",
    "Language modeling is framed as next-token prediction.\n",
    "\n",
    "Without sliding windows:\n",
    "- We would have only one training example.\n",
    "- The model would not generalize across positions.\n",
    "\n",
    "With sliding windows:\n",
    "- We create thousands of overlapping training signals.\n",
    "- The model learns conditional probabilities across contexts.\n",
    "\n",
    "This transforms a static text into dynamic supervision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b469634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 320\n",
      "Shape of one input: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "def create_input_target_pairs(token_ids, max_length=32, stride=16):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(0, len(token_ids) - max_length, stride):\n",
    "        input_chunk = token_ids[i : i + max_length]\n",
    "        target_chunk = token_ids[i + 1 : i + max_length + 1]\n",
    "        \n",
    "        inputs.append(torch.tensor(input_chunk))\n",
    "        targets.append(torch.tensor(target_chunk))\n",
    "    \n",
    "    return inputs, targets\n",
    "\n",
    "max_length = 32\n",
    "stride = 16\n",
    "\n",
    "inputs, targets = create_input_target_pairs(token_ids, max_length, stride)\n",
    "\n",
    "print(\"Number of samples:\", len(inputs))\n",
    "print(\"Shape of one input:\", inputs[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb8594",
   "metadata": {},
   "source": [
    "## Step 5: Creating a Dataset and DataLoader\n",
    "\n",
    "Here we encapsulate the sliding window logic inside a PyTorch Dataset class.\n",
    "\n",
    "This abstraction allows:\n",
    "\n",
    "- Indexable training samples\n",
    "- Modular data handling\n",
    "- Clean separation between data and model logic\n",
    "\n",
    "We then construct a DataLoader to:\n",
    "\n",
    "- Shuffle samples\n",
    "- Create mini-batches\n",
    "- Improve computational efficiency\n",
    "\n",
    "Why batching matters:\n",
    "\n",
    "Neural networks train via gradient descent.\n",
    "Mini-batching:\n",
    "\n",
    "- Stabilizes gradient updates\n",
    "- Enables GPU parallelism\n",
    "- Improves training efficiency\n",
    "\n",
    "This design mirrors large-scale LLM training pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d6cb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([4, 32])\n"
     ]
    }
   ],
   "source": [
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, token_ids, max_length, stride):\n",
    "        self.inputs, self.targets = create_input_target_pairs(\n",
    "            token_ids, max_length, stride\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "dataset = GPTDataset(token_ids, max_length=32, stride=16)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "batch_inputs, batch_targets = next(iter(dataloader))\n",
    "print(\"Batch input shape:\", batch_inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0315eb80",
   "metadata": {},
   "source": [
    "## Step 6: Token Embeddings with PyTorch\n",
    "\n",
    "In this section, we define a trainable embedding layer.\n",
    "\n",
    "Each token ID selects a row from an embedding matrix:\n",
    "\n",
    "$E \\in \\mathbb{R}^{V \\times d}$\n",
    "\n",
    "This converts discrete symbols into dense vectors.\n",
    "\n",
    "Why this transformation is fundamental:\n",
    "\n",
    "Token IDs are arbitrary integers.\n",
    "They carry no semantic meaning.\n",
    "\n",
    "Embeddings create:\n",
    "\n",
    "- Continuous vector representations\n",
    "- Differentiable structures\n",
    "- A geometric space where similarity can be measured\n",
    "\n",
    "This is the first learned layer of the model.\n",
    "\n",
    "It is the bridge between symbolic language and neural computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf1f8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded batch shape: torch.Size([4, 32, 64])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = tokenizer.n_vocab\n",
    "embedding_dim = 64\n",
    "\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "embedded_tokens = embedding_layer(batch_inputs)\n",
    "\n",
    "print(\"Embedded batch shape:\", embedded_tokens.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b029f",
   "metadata": {},
   "source": [
    "## Theoretical Foundations of Embedding Representations\n",
    "\n",
    "### Why Tokenization and Windows Matter\n",
    "\n",
    "\n",
    "Large Language Models (LLMs) do not operate on raw text. They operate on *discrete symbolic units* called tokens. Tokenization converts natural language into integer identifiers that can be processed mathematically.\n",
    "\n",
    "This transformation is essential because neural networks require numerical input. A model cannot directly reason over strings like \"painting\" or \"donkey\" - it must operate over vectors and tensors.\n",
    "\n",
    "The sliding window mechanism serves a second critical purpose: it converts a long sequence into many supervised training examples.\n",
    "\n",
    "Each input-target pair corresponds to a next-token prediction task:\n",
    "\n",
    "Input:  $x_0, x_1, x_2, ..., x_n$  \n",
    "Target: $x_1, x_2, x_3, ..., x_{n+1}$\n",
    "\n",
    "This structure is the foundation of autoregressive language modeling.\n",
    "\n",
    "Without sliding windows:\n",
    "- We would have only one extremely long sequence.\n",
    "- Training would be inefficient.\n",
    "- The model would not generalize across multiple local contexts.\n",
    "\n",
    "With sliding windows:\n",
    "- We create thousands of overlapping learning signals.\n",
    "- The model repeatedly learns how context predicts continuation.\n",
    "- We approximate the distribution P(next_token | context).\n",
    "\n",
    "This process transforms raw text into structured supervision.\n",
    "\n",
    "### From Tokens to Embeddings\n",
    "\n",
    "\n",
    "Token IDs are integers. However, integers alone do not encode semantic structure.\n",
    "\n",
    "The embedding layer transforms each token ID into a dense vector of fixed dimension:\n",
    "\n",
    "Embedding: $\\mathbb{Z}\\rarr\\mathbb{R}^d$\n",
    "\n",
    "Instead of representing the word \"painting\" as the scalar 1234, we represent it as a vector like:\n",
    "\n",
    "[0.12, -0.87, 0.44, ..., 0.03]\n",
    "\n",
    "This vector is *learned* during training.\n",
    "\n",
    "Why is this necessary?\n",
    "\n",
    "Neural networks operate through linear algebra. They compute:\n",
    "\n",
    "W &centerdot; x + b\n",
    "\n",
    "To do this meaningfully, tokens must live in a continuous vector space.\n",
    "\n",
    "Embeddings provide:\n",
    "- A continuous geometry\n",
    "- Differentiability\n",
    "- A structure that enables similarity comparisons\n",
    "\n",
    "This is the first moment where language becomes geometry.\n",
    "\n",
    "### Why Do Embeddings Encode Meaning?\n",
    "\n",
    "Embeddings encode meaning because of how they are trained.\n",
    "\n",
    "They are not manually assigned. They are optimized through gradient descent to minimize prediction error in next-token prediction tasks.\n",
    "\n",
    "If two words appear in similar contexts, the model must treat them similarly to reduce loss.\n",
    "\n",
    "Therefore:\n",
    "\n",
    "Words that share contexts &rarr; Receive similar gradient updates &rarr; Move closer in vector space.\n",
    "\n",
    "This is a consequence of:\n",
    "\n",
    "1. Distributional hypothesis (\"You shall know a word by the company it keeps.\")\n",
    "2. Shared parameterization in neural networks.\n",
    "3. Backpropagation aligning representations to minimize loss.\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "The embedding matrix is simply a lookup table:\n",
    "$E\\in\\mathbb{R}^{V\\times d}$\n",
    "\n",
    "Selecting a token corresponds to selecting a row.\n",
    "\n",
    "During training:\n",
    "- Prediction errors propagate backward.\n",
    "- Embedding rows are adjusted.\n",
    "- Geometric structure emerges.\n",
    "\n",
    "Thus, meaning is not stored symbolically.\n",
    "It is encoded geometrically as position in vector space.\n",
    "\n",
    "Embeddings are neural network parameters.\n",
    "They are the first learned layer of the model.\n",
    "They transform discrete symbols into continuous semantic structure.\n",
    "\n",
    "### Connection to Agentic Systems\n",
    "\n",
    "Embeddings are not only foundational for LLMs - they are foundational for agentic systems.\n",
    "\n",
    "In agentic architectures, embeddings enable:\n",
    "\n",
    "1. Memory retrieval (vector databases)\n",
    "2. Tool selection\n",
    "3. Context compression\n",
    "4. Semantic search\n",
    "5. Planning based on similarity\n",
    "\n",
    "When an agent retrieves relevant documents, it compares embeddings using cosine similarity.\n",
    "\n",
    "Without embeddings:\n",
    "- There is no semantic memory.\n",
    "- No similarity reasoning.\n",
    "- No contextual retrieval.\n",
    "\n",
    "In modern agent systems:\n",
    "Text &rarr; Embedding &rarr; Vector store &rarr; Similarity search &rarr; Augmented context &rarr; LLM reasoning\n",
    "\n",
    "Thus, embeddings form the bridge between:\n",
    "- Raw experience\n",
    "- Stored memory\n",
    "- Reasoned action\n",
    "\n",
    "They are the geometric substrate of intelligent behavior.\n",
    "\n",
    "## Step 7: Experiment: Changing max_length and stride\n",
    "\n",
    "max_length controls the context window size.\n",
    "stride controls how much overlap exists between samples.\n",
    "\n",
    "If stride == max_length:\n",
    "- No overlap\n",
    "- Fewer samples\n",
    "- Less redundancy\n",
    "- Lower training signal density\n",
    "\n",
    "If stride < max_length:\n",
    "- Overlapping windows\n",
    "- More samples\n",
    "- Higher computational cost\n",
    "- Better context continuity\n",
    "\n",
    "Why is overlap important?\n",
    "\n",
    "Because language dependencies span across boundaries.\n",
    "\n",
    "Without overlap:\n",
    "The model may not see transitions between chunks.\n",
    "\n",
    "With overlap:\n",
    "The same tokens appear in multiple contexts.\n",
    "This stabilizes training and improves generalization.\n",
    "\n",
    "Trade-off:\n",
    "More overlap &rarr; Better learning signal &rarr; Higher compute.\n",
    "Less overlap &rarr; Faster training &rarr; Less contextual smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12190e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length=32, stride=32 -> samples=160\n",
      "max_length=32, stride=16 -> samples=320\n",
      "max_length=64, stride=32 -> samples=159\n",
      "max_length=64, stride=64 -> samples=80\n"
     ]
    }
   ],
   "source": [
    "def count_samples(token_ids, max_length, stride):\n",
    "    count = 0\n",
    "    for i in range(0, len(token_ids) - max_length, stride):\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "configs = [\n",
    "    (32, 32),\n",
    "    (32, 16),\n",
    "    (64, 32),\n",
    "    (64, 64),\n",
    "]\n",
    "\n",
    "for max_len, stride in configs:\n",
    "    n_samples = count_samples(token_ids, max_len, stride)\n",
    "    print(f\"max_length={max_len}, stride={stride} -> samples={n_samples}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
